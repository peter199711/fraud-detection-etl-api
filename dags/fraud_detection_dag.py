"""
è©æ¬ºåµæ¸¬ ETL å’Œæ¨¡å‹è¨“ç·´ DAG
é€™å€‹ DAG è² è²¬å®šæœŸåŸ·è¡Œæ•¸æ“šè¼‰å…¥ã€ç‰¹å¾µå·¥ç¨‹å’Œæ¨¡å‹é‡æ–°è¨“ç·´

ä½œè€…: Fraud Detection Team  
æ—¥æœŸ: 2025-09-30

ä¿®æ­£ç‰ˆæœ¬ï¼š
- ä½¿ç”¨ Airflow Connections ç®¡ç†è³‡æ–™åº«é€£ç·š
- æ·»åŠ  feature_transactions VIEW å‰µå»ºæ­¥é©Ÿ
- æ”¹å–„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import Variable
import sys
import os

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append('/opt/airflow/src')

# é è¨­åƒæ•¸
default_args = {
    'owner': 'fraud-detection-team',
    'depends_on_past': False,
    'start_date': datetime(2025, 9, 30),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# å»ºç«‹ DAG
dag = DAG(
    'fraud_detection_pipeline',
    default_args=default_args,
    description='è©æ¬ºåµæ¸¬è³‡æ–™ç®¡é“å’Œæ¨¡å‹è¨“ç·´',
    schedule_interval=timedelta(days=1),  # æ¯æ—¥åŸ·è¡Œ
    catchup=False,  # ä¸è¿½è£œæ­·å²åŸ·è¡Œ
    tags=['fraud-detection', 'etl', 'ml'],
)

# ä»»å‹™ 1: æª¢æŸ¥è³‡æ–™åº«é€£ç·š (ä½¿ç”¨ Airflow Connections)
def check_database_connection():
    """ä½¿ç”¨ Airflow PostgresHook æª¢æŸ¥è³‡æ–™åº«é€£ç·š"""
    try:
        # ä½¿ç”¨ Airflow Connection ID 'postgres_fraud_db'
        postgres_hook = PostgresHook(postgres_conn_id='postgres_fraud_db')
        
        # æ¸¬è©¦é€£ç·š
        conn = postgres_hook.get_conn()
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        result = cursor.fetchone()
        cursor.close()
        conn.close()
        
        print("âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸ")
        print(f"æ¸¬è©¦æŸ¥è©¢çµæœ: {result}")
        return True
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        print("è«‹ç¢ºèª Airflow Connection 'postgres_fraud_db' å·²æ­£ç¢ºé…ç½®")
        raise

# ä»»å‹™ 2: è¼‰å…¥æ–°æ•¸æ“š (ä½¿ç”¨ BashOperator)
# ç§»é™¤ Python å‡½å¼ï¼Œæ”¹ç”¨ BashOperator åŸ·è¡Œ db_load.py è…³æœ¬

# ä»»å‹™ 3: å‰µå»ºç‰¹å¾µè¦–åœ– 
def create_feature_view():
    """å‰µå»ºæˆ–æ›´æ–° feature_transactions è¦–åœ–"""
    postgres_hook = PostgresHook(postgres_conn_id='postgres_fraud_db')
    
    # ç‰¹å¾µè¦–åœ– SQL
    create_view_sql = """
    CREATE OR REPLACE VIEW feature_transactions AS
    SELECT 
        time,
        v1, v2, v3, v4, v5, v6, v7, v8, v9, v10,
        v11, v12, v13, v14, v15, v16, v17, v18, v19, v20,
        v21, v22, v23, v24, v25, v26, v27, v28,
        amount,
        class
    FROM raw_transactions
    WHERE 
        time IS NOT NULL 
        AND amount IS NOT NULL
        AND class IS NOT NULL
    ORDER BY time;
    """
    
    try:
        print("ğŸ”§ å‰µå»º/æ›´æ–° feature_transactions è¦–åœ–...")
        
        # å…ˆåˆªé™¤ç¾æœ‰è¦–åœ–ä»¥é¿å…è¡çª
        drop_view_sql = "DROP VIEW IF EXISTS feature_transactions CASCADE;"
        postgres_hook.run(drop_view_sql)
        print("å·²åˆªé™¤ç¾æœ‰è¦–åœ–")
        
        # å‰µå»ºæ–°è¦–åœ–
        postgres_hook.run(create_view_sql)
        
        # é©—è­‰è¦–åœ–å‰µå»ºæˆåŠŸ
        count_query = "SELECT COUNT(*) FROM feature_transactions"
        result = postgres_hook.get_first(count_query)
        
        print(f"âœ… feature_transactions è¦–åœ–å‰µå»ºæˆåŠŸï¼ŒåŒ…å« {result[0]} ç­†è¨˜éŒ„")
        return True
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾µè¦–åœ–å‰µå»ºå¤±æ•—: {e}")
        raise

# ä»»å‹™ 4: åŸ·è¡Œæ¨¡å‹è¨“ç·´ (ä½¿ç”¨ BashOperator)
# ç§»é™¤ Python å‡½å¼ï¼Œæ”¹ç”¨ BashOperator åŸ·è¡Œè…³æœ¬

# ä»»å‹™ 5: é©—è­‰æ¨¡å‹æ€§èƒ½
def validate_model_performance():
    """é©—è­‰æ¨¡å‹æ€§èƒ½æ˜¯å¦ç¬¦åˆæ¨™æº–"""
    postgres_hook = PostgresHook(postgres_conn_id='postgres_fraud_db')
    
    print("ğŸ“Š é©—è­‰æ¨¡å‹æ€§èƒ½...")
    # é€™è£¡å¯ä»¥æ·»åŠ å¯¦éš›çš„æ¨¡å‹é©—è­‰é‚è¼¯
    # ä¾‹å¦‚å¾ MLflow è¼‰å…¥æœ€æ–°æ¨¡å‹ä¸¦æª¢æŸ¥ F1 score, AUC ç­‰æŒ‡æ¨™
    
    # ç°¡å–®æª¢æŸ¥ï¼šç¢ºä¿æœ‰è¶³å¤ çš„è¨“ç·´æ•¸æ“š
    try:
        count_query = "SELECT COUNT(*) FROM feature_transactions WHERE class = 1"
        fraud_count = postgres_hook.get_first(count_query)[0]
        
        if fraud_count < 100:
            print(f"âš ï¸  è­¦å‘Šï¼šè©æ¬ºæ¡ˆä¾‹æ•¸é‡è¼ƒå°‘ ({fraud_count} ç­†)")
        else:
            print(f"âœ… è©æ¬ºæ¡ˆä¾‹æ•¸é‡å……è¶³ï¼š{fraud_count} ç­†")
            
        print("âœ… æ¨¡å‹æ€§èƒ½é©—è­‰å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹é©—è­‰å¤±æ•—: {e}")
        raise

# ä»»å‹™ 6: æ¸…ç†æš«å­˜æª”æ¡ˆ
cleanup_task = BashOperator(
    task_id='cleanup_temp_files',
    bash_command='echo "ğŸ§¹ æ¸…ç†æš«å­˜æª”æ¡ˆ..." && find /tmp -name "*fraud*" -type f -delete 2>/dev/null || true',
    dag=dag,
)

# å®šç¾©æ‰€æœ‰ä»»å‹™
db_check_task = PythonOperator(
    task_id='check_database_connection',
    python_callable=check_database_connection,
    dag=dag,
)

data_load_task = BashOperator(
    task_id='load_new_data',
    bash_command="""
    cd /opt/airflow/src && \
    export DB_HOST=postgres_db && \
    python -m etl.db_load
    """,
    dag=dag,
)

create_feature_view_task = PythonOperator(
    task_id='create_feature_view',
    python_callable=create_feature_view,
    dag=dag,
)

model_training_task = BashOperator(
    task_id='perform_model_training',
    bash_command="""
    cd /opt/airflow/src && \
    export DB_HOST=postgres_db && \
    export MLFLOW_HOST=mlflow_server && \
    python -m etl.transform_data
    """,
    dag=dag,
)

model_validation_task = PythonOperator(
    task_id='validate_model_performance',
    python_callable=validate_model_performance,
    dag=dag,
)

# ä¿®æ­£å¾Œçš„ä»»å‹™ä¾è³´é—œä¿‚
db_check_task >> data_load_task >> create_feature_view_task >> model_training_task >> model_validation_task >> cleanup_task

# æ·»åŠ ä»»å‹™æ–‡æª”
db_check_task.doc_md = """
æª¢æŸ¥ PostgreSQL è³‡æ–™åº«æ˜¯å¦å¯æ­£å¸¸é€£ç·š
ä½¿ç”¨ Airflow PostgresHook å’Œ Connection 'postgres_fraud_db'
"""

data_load_task.doc_md = """
åŸ·è¡Œè³‡æ–™è¼‰å…¥è…³æœ¬ (db_load.py)
é‡æ–°è¼‰å…¥ä¿¡ç”¨å¡äº¤æ˜“æ•¸æ“šä¸¦å‰µå»ºåŸºç¤ raw_transactions è¡¨
"""

create_feature_view_task.doc_md = """
å‰µå»ºæˆ–æ›´æ–° feature_transactions è¦–åœ–
é€™å€‹è¦–åœ–æ˜¯æ¨¡å‹è¨“ç·´çš„æ ¸å¿ƒæ•¸æ“šä¾†æºï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„ç‰¹å¾µ
"""

model_training_task.doc_md = """
åŸ·è¡Œæ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´è…³æœ¬ (transform_data.py)
ä½¿ç”¨ feature_transactions è¦–åœ–è¨“ç·´å¤šå€‹æ¨¡å‹ä¸¦å°‡æœ€ä½³æ¨¡å‹è¨˜éŒ„åˆ° MLflow
"""

model_validation_task.doc_md = """
é©—è­‰æ–°è¨“ç·´æ¨¡å‹çš„æ€§èƒ½æŒ‡æ¨™
æª¢æŸ¥æ¨¡å‹å“è³ªå’Œæ•¸æ“šå®Œæ•´æ€§
"""

cleanup_task.doc_md = """
æ¸…ç†åŸ·è¡Œéç¨‹ä¸­ç”¢ç”Ÿçš„æš«å­˜æª”æ¡ˆ
ç¶­è­·ç³»çµ±æ•´æ½”ï¼Œé‡‹æ”¾ç£ç¢Ÿç©ºé–“
"""
