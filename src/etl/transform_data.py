import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score
from sqlalchemy import create_engine
import joblib
import os
import mlflow
import mlflow.sklearn
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# å°å…¥ TensorFlow æ¨¡å‹æ¨¡çµ„
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from models.tensorflow_model import train_tensorflow_model

# --- è¨­å®šè·¯å¾‘èˆ‡åƒæ•¸ ---
# å„²å­˜æœ€çµ‚æ¨¡å‹çš„æœ¬åœ°è·¯å¾‘
# ç’°å¢ƒè‡ªé©æ‡‰ï¼šæœ¬æ©Ÿä½¿ç”¨ç›¸å°è·¯å¾‘ï¼ŒDocker ä½¿ç”¨çµ•å°è·¯å¾ª
if os.path.exists('/opt/airflow'):
    # Docker ç’°å¢ƒï¼šä½¿ç”¨ /opt/airflow/src/modelsï¼ˆå°æ‡‰æœ¬æ©Ÿçš„ src/modelsï¼‰
    MODEL_PATH = os.getenv('MODEL_PATH', '/opt/airflow/src/models/baseline_model.pkl')
else:
    # æœ¬æ©Ÿç’°å¢ƒï¼šä½¿ç”¨ç›¸å°è·¯å¾‘
    MODEL_PATH = os.getenv('MODEL_PATH', 'src/models/baseline_model.pkl')

# --- æ”¹é€²ï¼šå¾ç’°å¢ƒè®Šæ•¸è®€å–ä¸»æ©Ÿåç¨±ï¼Œä¸¦æä¾›æœ¬åœ°é è¨­å€¼ ---
DB_HOST = os.getenv('DB_HOST', 'localhost')
# å„ªå…ˆè®€å–å®Œæ•´çš„ URIï¼Œå¦‚æœæ²’æœ‰æ‰ç”¨ HOST æ§‹å»º
MLFLOW_TRACKING_URI = os.getenv('MLFLOW_TRACKING_URI')
if not MLFLOW_TRACKING_URI:
    MLFLOW_HOST = os.getenv('MLFLOW_HOST', 'localhost')
    MLFLOW_TRACKING_URI = f"http://{MLFLOW_HOST}:5000"

print(f"ğŸ”— ä½¿ç”¨ MLflow URI: {MLFLOW_TRACKING_URI}")  # æ·»åŠ èª¿è©¦è¼¸å‡º

# è³‡æ–™åº«é€£ç·šåƒæ•¸
DB_NAME = os.getenv('DB_NAME', 'fraud_db')
DB_USER = os.getenv('DB_USER', 'user')
DB_PASSWORD = os.getenv('DB_PASSWORD', 'password')
DB_PORT = '5432'
DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
FEATURE_VIEW_NAME = 'feature_transactions'


def load_data(engine):
    """å¾ PostgreSQL feature_transactions è¦–åœ–è¼‰å…¥æ•¸æ“šä¸¦åˆ†å‰²ã€‚"""
    
    print(f"--- 1. å¾è³‡æ–™åº«è¼‰å…¥ç‰¹å¾µï¼š{FEATURE_VIEW_NAME} ---")
    
    sql_query = f"SELECT * FROM {FEATURE_VIEW_NAME}"
    df = pd.read_sql(sql_query, engine)
    
    print(f"æˆåŠŸè¼‰å…¥ {len(df)} ç­†ç‰¹å¾µæ•¸æ“šã€‚")

    X = df.drop('class', axis=1)
    y = df['class']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    return X_train, X_test, y_train, y_test

def train_model_and_log_mlflow(model_class, run_name, params, tags, X_train, X_test, y_train, y_test):
    """è¨“ç·´å–®ä¸€æ¨¡å‹ã€è©•ä¼°ä¸¦å°‡çµæœè¨˜éŒ„åˆ° MLflowã€‚"""
    
    with mlflow.start_run(run_name=run_name) as run:
        print(f"\n--- è¨“ç·´: {run_name} ---")

        # è¨˜éŒ„åƒæ•¸å’Œæ¨™ç±¤
        mlflow.log_params(params)
        mlflow.set_tags(tags) 
        
        # è¨“ç·´æ¨¡å‹
        model = model_class(**params) 
        model.fit(X_train, y_train)
        
        # è©•ä¼°æ¨¡å‹
        y_proba = model.predict_proba(X_test)[:, 1]
        y_pred = (y_proba > 0.5).astype(int) 
        
        metrics = {
            "roc_auc_score": roc_auc_score(y_test, y_proba),
            "f1_score": f1_score(y_test, y_pred),
            "precision_score": precision_score(y_test, y_pred),
            "recall_score": recall_score(y_test, y_pred)
        }
        mlflow.log_metrics(metrics)

        print(f"   AUC: {metrics['roc_auc_score']:.4f}, F1: {metrics['f1_score']:.4f}, Precision: {metrics['precision_score']:.4f}")

        # âœ… å„²å­˜æ¨¡å‹åˆ° MLflow Artifactsï¼ˆæ¸¬è©¦é€£æ¥ï¼‰
        try:
            # å…ˆæ¸¬è©¦åŸºæœ¬é€£æ¥
            client = mlflow.tracking.MlflowClient()
            print(f"MLflow å®¢æˆ¶ç«¯é€£æ¥æˆåŠŸ")
            
            # ä½¿ç”¨æœ€ç°¡å–®çš„æ–¹æ³•è¨˜éŒ„æ¨¡å‹
            mlflow.sklearn.log_model(model, "model")
            print(f"æˆåŠŸè¨˜éŒ„ {tags.get('model_type', 'Unknown')} æ¨¡å‹åˆ° MLflow")
        except Exception as e:
            print(f"æ¨¡å‹è¨˜éŒ„å¤±æ•—: {e}")
            print(f"è·³éæ¨¡å‹è¨˜éŒ„ï¼Œä½†è¨“ç·´æŒ‡æ¨™å·²ä¿å­˜")
        
        return metrics['f1_score'], model


def run_etl_and_train_pipeline():
    """ä¸»åŸ·è¡Œå‡½å¼ï¼ŒåŒ…å«æ•¸æ“šè¼‰å…¥å’Œæ‰€æœ‰æ¨¡å‹çš„è¨“ç·´ã€‚"""

    global MODEL_PATH  # â† æ·»åŠ é€™è¡Œ

    print(f"è¨­å®š MLflow Tracking URI: {MLFLOW_TRACKING_URI}")
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    mlflow.set_experiment("Fraud Detection Baseline") 
    try:
        os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
        print(f"ğŸ“ æ¨¡å‹å„²å­˜ç›®éŒ„å·²æº–å‚™ï¼š{os.path.dirname(MODEL_PATH)}")
    except PermissionError:
        print(f"âš ï¸  ç„¡æ³•å‰µå»ºç›®éŒ„ {os.path.dirname(MODEL_PATH)}ï¼Œä½¿ç”¨ç•¶å‰ç›®éŒ„")
        MODEL_PATH = 'baseline_model.pkl'
    
    try:
        engine = create_engine(DATABASE_URL)
        # æ¸¬è©¦é€£ç·š
        connection = engine.connect()
        print(f"æˆåŠŸé€£ç·šåˆ°è³‡æ–™åº«ï¼š{DB_HOST}/{DB_NAME}")
        connection.close()

        # 1. è¼‰å…¥å’Œåˆ†å‰²æ•¸æ“š
        X_train, X_test, y_train, y_test = load_data(engine)

        best_f1_score = -1
        best_model = None
        best_model_name = ""

        # 2. æ¨¡å‹é…ç½®æ¸…å–®
        model_configs = [
            {
                "name": "01_Logistic_Regression_Baseline",
                "class": LogisticRegression,
                "params": {"solver": 'liblinear', "random_state": 42, "class_weight": 'balanced'},
                "tags": {"data_source": "Postgres-VIEW", "model_type": "LogisticRegression"},
                "type": "sklearn"
            },
            {
                "name": "02_XGBoost_Optimized",
                "class": XGBClassifier,
                "params": {
                    'n_estimators': 100, 
                    'learning_rate': 0.1, 
                    'scale_pos_weight': 50,
                    'random_state': 42,
                    'use_label_encoder': False,
                    'eval_metric': 'logloss'
                },
                "tags": {"data_source": "Postgres-VIEW", "model_type": "XGBoost"},
                "type": "sklearn"
            },
            {
                "name": "03_LightGBM_Optimized",
                "class": LGBMClassifier, 
                "params": {
                    'n_estimators': 200, 
                    'learning_rate': 0.05, 
                    'scale_pos_weight': 40, 
                    'random_state': 42
                },
                "tags": {"data_source": "Postgres-VIEW", "model_type": "LightGBM"},
                "type": "sklearn"
            },
            {
                "name": "04_TensorFlow_DNN",
                "class": None,  # TensorFlow ä½¿ç”¨è‡ªè¨‚è¨“ç·´å‡½å¼
                "params": {
                    'epochs': 50,
                    'batch_size': 256,
                    'learning_rate': 0.001,
                    'early_stopping_patience': 10
                },
                "tags": {"data_source": "Postgres-VIEW", "model_type": "TensorFlow"},
                "type": "tensorflow"
            }
        ]

        # 3. è¿­ä»£è¨“ç·´æ‰€æœ‰æ¨¡å‹
        for config in model_configs:
            # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡è¨“ç·´æ–¹å¼
            if config.get("type") == "tensorflow":
                # TensorFlow æ¨¡å‹ä½¿ç”¨å°ˆç”¨è¨“ç·´å‡½å¼
                try:
                    current_f1, current_model = train_tensorflow_model(
                        X_train=X_train, 
                        X_test=X_test, 
                        y_train=y_train, 
                        y_test=y_test,
                        run_name=config["name"],
                        tags=config["tags"],
                        **config["params"]
                    )
                except Exception as tf_error:
                    print(f"âš ï¸  TensorFlow æ¨¡å‹è¨“ç·´å¤±æ•—: {tf_error}")
                    print("ç¹¼çºŒè¨“ç·´å…¶ä»–æ¨¡å‹...")
                    continue
            else:
                # sklearn/XGBoost/LightGBM æ¨¡å‹ä½¿ç”¨åŸæœ‰å‡½å¼
                current_f1, current_model = train_model_and_log_mlflow(
                    model_class=config["class"],
                    run_name=config["name"],
                    params=config["params"],
                    tags=config["tags"],
                    X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test
                )
            
            # 4. é¸æ“‡ä¸¦å„²å­˜æœ€ä½³æ¨¡å‹
            if current_f1 > best_f1_score:
                best_f1_score = current_f1
                best_model = current_model
                best_model_name = config["name"]
                print(f"-> æ–°çš„æœ€ä½³æ¨¡å‹: {best_model_name} (F1={best_f1_score:.4f})")

        if best_model:
            # é€™è£¡æˆ‘å€‘ä¸å†éœ€è¦å„²å­˜åˆ°æœ¬åœ°ï¼Œå› ç‚º API å°‡æœƒå¾ MLflow è¼‰å…¥æ¨¡å‹
            # joblib.dump(best_model, MODEL_PATH) 
            print(f"\nâœ… è¨“ç·´æµç¨‹å®Œæˆã€‚æœ€ä½³æ¨¡å‹ '{best_model_name}' å·²è¨˜éŒ„è‡³ MLflowã€‚")
            print("API æœå‹™ç¾åœ¨æ‡‰è©²èƒ½å¤ å¾ MLflow è¼‰å…¥æ­¤æ¨¡å‹ã€‚")

    except Exception as e:
        import traceback
        print(f"\nğŸ”¥ è¨“ç·´æµç¨‹å¤±æ•—ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        print(traceback.format_exc())
        print("è«‹ç¢ºèª MLflow Server (mlflow_server) å’Œ PostgreSQL (postgres_db) å®¹å™¨æ­£åœ¨é‹è¡Œã€‚")

def main():
    """ä¸»åŸ·è¡Œå‡½å¼ - ä¾› Airflow DAG å‘¼å«"""
    try:
        run_etl_and_train_pipeline()
        # æ˜ç¢ºæŒ‡å®šæˆåŠŸé€€å‡ºï¼Œå³ä½¿ MLflow API æœ‰å•é¡Œ
        print("ğŸ¯ ä¸»å‡½æ•¸åŸ·è¡Œå®Œæˆï¼Œå¼·åˆ¶è¿”å›æˆåŠŸç‹€æ…‹")
        import sys
        sys.exit(0)
    except Exception as e:
        import traceback
        print(f"ğŸ”¥ ä¸»å‡½æ•¸åŸ·è¡Œå¤±æ•—: {e}")
        print(traceback.format_exc())
        import sys
        sys.exit(1)

if __name__ == "__main__":
    main()
