import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score
from sqlalchemy import create_engine
import joblib
import os
import mlflow
import mlflow.sklearn
from xgboost import XGBClassifier

# --- è¨­å®šè·¯å¾‘èˆ‡åƒæ•¸ ---
# å„²å­˜æœ€çµ‚æ¨¡å‹çš„æœ¬åœ°è·¯å¾‘
MODEL_PATH = '/app/src/models/baseline_model.pkl' # ä½¿ç”¨å®¹å™¨å…§çš„çµ•å°è·¯å¾‘

# --- æ”¹é€²ï¼šå¾ç’°å¢ƒè®Šæ•¸è®€å–ä¸»æ©Ÿåç¨±ï¼Œä¸¦æä¾›æœ¬åœ°é è¨­å€¼ ---
DB_HOST = os.getenv('DB_HOST', 'localhost')
MLFLOW_HOST = os.getenv('MLFLOW_HOST', 'localhost')

# MLflow è¿½è¹¤æœå‹™çš„ URI
MLFLOW_TRACKING_URI = f"http://{MLFLOW_HOST}:5000" 

# è³‡æ–™åº«é€£ç·šåƒæ•¸
DB_NAME = os.getenv('DB_NAME', 'fraud_db')
DB_USER = os.getenv('DB_USER', 'user')
DB_PASSWORD = os.getenv('DB_PASSWORD', 'password')
DB_PORT = '5432'
DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
FEATURE_VIEW_NAME = 'feature_transactions'


def load_data(engine):
    """å¾ PostgreSQL feature_transactions è¦–åœ–è¼‰å…¥æ•¸æ“šä¸¦åˆ†å‰²ã€‚"""
    
    print(f"--- 1. å¾è³‡æ–™åº«è¼‰å…¥ç‰¹å¾µï¼š{FEATURE_VIEW_NAME} ---")
    
    sql_query = f"SELECT * FROM {FEATURE_VIEW_NAME}"
    df = pd.read_sql(sql_query, engine)
    
    print(f"æˆåŠŸè¼‰å…¥ {len(df)} ç­†ç‰¹å¾µæ•¸æ“šã€‚")

    X = df.drop('class', axis=1)
    y = df['class']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    return X_train, X_test, y_train, y_test

def train_model_and_log_mlflow(model_class, run_name, params, tags, X_train, X_test, y_train, y_test):
    """è¨“ç·´å–®ä¸€æ¨¡å‹ã€è©•ä¼°ä¸¦å°‡çµæœè¨˜éŒ„åˆ° MLflowã€‚"""
    
    with mlflow.start_run(run_name=run_name) as run:
        print(f"\n--- è¨“ç·´: {run_name} ---")

        # è¨˜éŒ„åƒæ•¸å’Œæ¨™ç±¤
        mlflow.log_params(params)
        mlflow.set_tags(tags) 
        
        # è¨“ç·´æ¨¡å‹
        model = model_class(**params) 
        model.fit(X_train, y_train)
        
        # è©•ä¼°æ¨¡å‹
        y_proba = model.predict_proba(X_test)[:, 1]
        y_pred = (y_proba > 0.5).astype(int) 
        
        metrics = {
            "roc_auc_score": roc_auc_score(y_test, y_proba),
            "f1_score": f1_score(y_test, y_pred),
            "precision_score": precision_score(y_test, y_pred),
            "recall_score": recall_score(y_test, y_pred)
        }
        mlflow.log_metrics(metrics)

        print(f"   AUC: {metrics['roc_auc_score']:.4f}, F1: {metrics['f1_score']:.4f}, Precision: {metrics['precision_score']:.4f}")

        # å„²å­˜æ¨¡å‹åˆ° MLflow Artifacts
        mlflow.sklearn.log_model(model, "model")
        
        return metrics['f1_score'], model


def run_etl_and_train_pipeline():
    """ä¸»åŸ·è¡Œå‡½å¼ï¼ŒåŒ…å«æ•¸æ“šè¼‰å…¥å’Œæ‰€æœ‰æ¨¡å‹çš„è¨“ç·´ã€‚"""
    
    print(f"è¨­å®š MLflow Tracking URI: {MLFLOW_TRACKING_URI}")
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    mlflow.set_experiment("Fraud Detection Baseline") 
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    
    try:
        engine = create_engine(DATABASE_URL)
        # æ¸¬è©¦é€£ç·š
        connection = engine.connect()
        print(f"æˆåŠŸé€£ç·šåˆ°è³‡æ–™åº«ï¼š{DB_HOST}/{DB_NAME}")
        connection.close()

        # 1. è¼‰å…¥å’Œåˆ†å‰²æ•¸æ“š
        X_train, X_test, y_train, y_test = load_data(engine)

        best_f1_score = -1
        best_model = None
        best_model_name = ""

        # 2. æ¨¡å‹é…ç½®æ¸…å–®
        model_configs = [
            {
                "name": "01_Logistic_Regression_Baseline",
                "class": LogisticRegression,
                "params": {"solver": 'liblinear', "random_state": 42, "class_weight": 'balanced'},
                "tags": {"data_source": "Postgres-VIEW", "model_type": "LogisticRegression"}
            },
            {
                "name": "02_XGBoost_Optimized",
                "class": XGBClassifier,
                "params": {
                    'n_estimators': 100, 
                    'learning_rate': 0.1, 
                    'scale_pos_weight': 50,
                    'random_state': 42,
                    'use_label_encoder': False,
                    'eval_metric': 'logloss'
                },
                "tags": {"data_source": "Postgres-VIEW", "model_type": "XGBoost"}
            }
        ]

        # 3. è¿­ä»£è¨“ç·´æ‰€æœ‰æ¨¡å‹
        for config in model_configs:
            current_f1, current_model = train_model_and_log_mlflow(
                model_class=config["class"],
                run_name=config["name"],
                params=config["params"],
                tags=config["tags"],
                X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test
            )
            
            # 4. é¸æ“‡ä¸¦å„²å­˜æœ€ä½³æ¨¡å‹
            if current_f1 > best_f1_score:
                best_f1_score = current_f1
                best_model = current_model
                best_model_name = config["name"]
                print(f"-> æ–°çš„æœ€ä½³æ¨¡å‹: {best_model_name} (F1={best_f1_score:.4f})")

        if best_model:
            # é€™è£¡æˆ‘å€‘ä¸å†éœ€è¦å„²å­˜åˆ°æœ¬åœ°ï¼Œå› ç‚º API å°‡æœƒå¾ MLflow è¼‰å…¥æ¨¡å‹
            # joblib.dump(best_model, MODEL_PATH) 
            print(f"\nâœ… è¨“ç·´æµç¨‹å®Œæˆã€‚æœ€ä½³æ¨¡å‹ '{best_model_name}' å·²è¨˜éŒ„è‡³ MLflowã€‚")
            print("API æœå‹™ç¾åœ¨æ‡‰è©²èƒ½å¤ å¾ MLflow è¼‰å…¥æ­¤æ¨¡å‹ã€‚")

    except Exception as e:
        import traceback
        print(f"\nğŸ”¥ è¨“ç·´æµç¨‹å¤±æ•—ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        print(traceback.format_exc())
        print("è«‹ç¢ºèª MLflow Server (mlflow_server) å’Œ PostgreSQL (postgres_db) å®¹å™¨æ­£åœ¨é‹è¡Œã€‚")

if __name__ == "__main__":
    run_etl_and_train_pipeline()
